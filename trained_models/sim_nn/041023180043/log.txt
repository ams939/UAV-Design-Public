18:00:45 main: Beginning experiment ID 041023180043 of type 'traineval'

18:00:45 main: Using hyperparams: {
    "hparam_file": "hparams/nn_hparams.json",
    "hparams_file": "nn_hparams.json",
    "experiment_id": "041023180043",
    "device": "cpu",
    "experiment_type": "traineval",
    "experiment_folder": "./experiments/SimNN/041023180043",
    "model_class": "model.NN.MHSimNN",
    "feature_dim": 295,
    "model_hparams": {
        "fc_hparams": {
            "hidden_sizes": [
                1024,
                2048,
                1024
            ]
        },
        "reg_hparams": {
            "hidden_sizes": [
                512,
                512,
                256,
                128
            ]
        },
        "clf_hparams": {
            "hidden_sizes": [
                512,
                128,
                32,
                8
            ]
        }
    },
    "dropout": 0.0,
    "num_outcomes": 1,
    "optimizer_class": "torch.optim.adam.Adam",
    "optimizer_hparams": {
        "lr": 0.001
    },
    "scheduler_class": "torch.optim.lr_scheduler.MultiStepLR",
    "scheduler_hparams": {
        "milestones": [
            20,
            1000
        ],
        "gamma": 0.1
    },
    "dataloader_hparams": {
        "batch_size": 256,
        "shuffle": true
    },
    "dataset_class": "data.UAVDataset.UAVMatrixDataset",
    "dataset_hparams": {
        "datafile": "data/datafiles/preprocessed/design_database_april.csv",
        "target_cols": [
            "range",
            "cost",
            "velocity",
            "result"
        ],
        "scale": true,
        "scaler_class": "sklearn.preprocessing._data.RobustScaler",
        "encoding_scheme": "matrix"
    },
    "n_folds": 4,
    "val_proportion": 0.2,
    "test_proportion": 0.1,
    "save_testset": false,
    "loss_class": "train.Loss.WeightedMAEBCELoss",
    "loss_hparams": {
        "pos_weight": 1
    },
    "loggers": [
        {
            "logger_class": "train.Logging.ConsoleLogger",
            "logger_hparams": {
                "mode": 1,
                "file_path": "./experiments/SimNN/041023180043"
            }
        },
        {
            "logger_class": "train.Logging.DatafileLogger",
            "logger_hparams": {
                "mode": 1,
                "file_path": "./experiments/SimNN/041023180043"
            }
        },
        {
            "logger_class": "train.Logging.FileLogger",
            "logger_hparams": {
                "mode": 1,
                "file_path": "./experiments/SimNN/041023180043"
            }
        },
        {
            "logger_class": "train.Logging.WandbLogger",
            "logger_hparams": {
                "mode": 1,
                "project_name": "uav-design",
                "file_path": "./experiments/SimNN/041023180043"
            }
        }
    ],
    "stoppers": [
        {
            "stopper_class": "train.TrainStopper.EpochStopper",
            "stopper_hparams": {
                "stop_epoch": 5000
            }
        },
        {
            "stopper_class": "train.TrainStopper.PlateauStopper",
            "stopper_hparams": {
                "patience": 20,
                "start_epoch": 100
            }
        }
    ],
    "simulator_class": "inference.NNSimulator.NNSimulator",
    "simulator_hparams": {
        "simulator_results_file": "sim_results.csv"
    },
    "postprocessor_class": "data.DataPostprocessor.UAVMatrixPostprocessor",
    "logger": "train.Logging.MultiLogger"
}

18:00:45 main: Beginning training experiment on device: cpu

18:00:45 MHSimNN: WARNING: No existing model found, new model created.

18:00:45 UAVMatrixDataset: Using encoding scheme 'matrix'

18:00:56 main: Raw data loaded from design_database_april.csv (383554 records) 

18:00:59 main: Splitting the dataset into a train and test set with 10% (38356 records) as the test set

18:01:03 main: Splitting train dataset into a train and validation set with 20% (69040 records) as the validation set, 276158 records in the train set.

18:01:05 Trainer: Training model using device cpu

18:01:05 Trainer: Using Adam optimizer with LR=0.001

18:01:05 Trainer: Using MultiStepLR learning rate scheduler with params milestones=[20, 1000],gamma=0.1

18:01:05 Trainer: Using WeightedMAEBCELoss loss function.

18:01:05 EpochStopper: Initializing with stopping condition epoch > 5000

18:01:05 PlateauStopper: Initializing with stopping condition: Loss does not decrease for 20 epochs

18:01:15 Trainer: Pre-training train-set loss 695.915

18:01:18 Trainer: Pre-training val-set loss 687.254

18:01:18 Trainer: Training epoch 1 beginning

18:02:36 Trainer: Training epoch 1 complete (78.560s). Train Loss: 427.04

18:02:39 Trainer: Validation loss: 356.32

18:02:39 EpochStopper: Stopper iterating

18:02:39 Trainer: Training epoch 2 beginning

18:04:31 Trainer: Training epoch 2 complete (112.052s). Train Loss: 339.46

18:04:34 Trainer: Validation loss: 331.47

18:04:34 EpochStopper: Stopper iterating

18:04:34 Trainer: Training epoch 3 beginning

18:06:27 Trainer: Training epoch 3 complete (113.923s). Train Loss: 311.62

18:06:30 Trainer: Validation loss: 307.95

18:06:30 EpochStopper: Stopper iterating

18:06:30 Trainer: Training epoch 4 beginning

18:08:24 Trainer: Training epoch 4 complete (114.231s). Train Loss: 293.45

18:08:27 Trainer: Validation loss: 298.75

18:08:27 EpochStopper: Stopper iterating

18:08:27 Trainer: Training epoch 5 beginning

18:10:22 Trainer: Training epoch 5 complete (115.300s). Train Loss: 280.04

18:10:25 Trainer: Validation loss: 291.38

18:10:25 EpochStopper: Stopper iterating

18:10:25 Trainer: Training epoch 6 beginning

18:12:11 Trainer: Training epoch 6 complete (105.684s). Train Loss: 268.62

18:12:13 Trainer: Validation loss: 285.39

18:12:13 EpochStopper: Stopper iterating

18:12:13 Trainer: Training epoch 7 beginning

18:14:07 Trainer: Training epoch 7 complete (113.532s). Train Loss: 258.95

18:14:09 Trainer: Validation loss: 282.17

18:14:09 EpochStopper: Stopper iterating

18:14:09 Trainer: Training epoch 8 beginning

18:16:01 Trainer: Training epoch 8 complete (112.175s). Train Loss: 251.24

18:16:04 Trainer: Validation loss: 283.65

18:16:04 EpochStopper: Stopper iterating

18:16:04 Trainer: Training epoch 9 beginning

18:17:57 Trainer: Training epoch 9 complete (112.981s). Train Loss: 243.17

18:18:00 Trainer: Validation loss: 282.30

18:18:00 EpochStopper: Stopper iterating

18:18:00 Trainer: Training epoch 10 beginning

18:19:52 Trainer: Training epoch 10 complete (111.795s). Train Loss: 236.97

18:19:55 Trainer: Validation loss: 275.75

18:19:55 EpochStopper: Stopper iterating

18:19:55 Trainer: Training epoch 11 beginning

18:21:46 Trainer: Training epoch 11 complete (111.915s). Train Loss: 229.54

18:21:49 Trainer: Validation loss: 270.16

18:21:49 EpochStopper: Stopper iterating

18:21:49 Trainer: Training epoch 12 beginning

18:23:43 Trainer: Training epoch 12 complete (113.459s). Train Loss: 223.61

18:23:45 Trainer: Validation loss: 270.32

18:23:45 EpochStopper: Stopper iterating

18:23:45 Trainer: Training epoch 13 beginning

18:25:37 Trainer: Training epoch 13 complete (111.632s). Train Loss: 217.13

18:25:39 Trainer: Validation loss: 269.60

18:25:39 EpochStopper: Stopper iterating

18:25:39 Trainer: Training epoch 14 beginning

18:27:35 Trainer: Training epoch 14 complete (115.385s). Train Loss: 212.95

18:27:37 Trainer: Validation loss: 267.56

18:27:37 EpochStopper: Stopper iterating

18:27:37 Trainer: Training epoch 15 beginning

18:29:28 Trainer: Training epoch 15 complete (110.235s). Train Loss: 208.00

18:29:30 Trainer: Validation loss: 264.88

18:29:30 EpochStopper: Stopper iterating

18:29:30 Trainer: Training epoch 16 beginning

18:31:27 Trainer: Training epoch 16 complete (117.014s). Train Loss: 203.82

18:31:30 Trainer: Validation loss: 267.53

18:31:30 EpochStopper: Stopper iterating

18:31:30 Trainer: Training epoch 17 beginning

18:33:28 Trainer: Training epoch 17 complete (117.881s). Train Loss: 199.91

18:33:30 Trainer: Validation loss: 263.79

18:33:30 EpochStopper: Stopper iterating

18:33:30 Trainer: Training epoch 18 beginning

18:35:28 Trainer: Training epoch 18 complete (117.446s). Train Loss: 194.85

18:35:30 Trainer: Validation loss: 266.96

18:35:30 EpochStopper: Stopper iterating

18:35:30 Trainer: Training epoch 19 beginning

18:37:33 Trainer: Training epoch 19 complete (122.332s). Train Loss: 191.58

18:37:36 Trainer: Validation loss: 265.25

18:37:36 EpochStopper: Stopper iterating

18:37:36 Trainer: Training epoch 20 beginning

18:39:40 Trainer: Learning rate updated from 0.001 to 0.0001

18:39:40 Trainer: Training epoch 20 complete (124.292s). Train Loss: 187.70

18:39:43 Trainer: Validation loss: 265.87

18:39:43 EpochStopper: Stopper iterating

18:39:43 Trainer: Training epoch 21 beginning

18:41:51 Trainer: Training epoch 21 complete (128.537s). Train Loss: 162.66

18:41:54 Trainer: Validation loss: 250.31

18:41:54 EpochStopper: Stopper iterating

18:41:54 Trainer: Training epoch 22 beginning

18:44:05 Trainer: Training epoch 22 complete (131.142s). Train Loss: 149.29

18:44:08 Trainer: Validation loss: 248.77

18:44:08 EpochStopper: Stopper iterating

18:44:08 Trainer: Training epoch 23 beginning

18:46:18 Trainer: Training epoch 23 complete (130.870s). Train Loss: 142.21

18:46:21 Trainer: Validation loss: 248.17

18:46:21 EpochStopper: Stopper iterating

18:46:21 Trainer: Training epoch 24 beginning

18:48:34 Trainer: Training epoch 24 complete (132.724s). Train Loss: 136.99

18:48:37 Trainer: Validation loss: 247.23

18:48:37 EpochStopper: Stopper iterating

18:48:37 Trainer: Training epoch 25 beginning

18:50:50 Trainer: Training epoch 25 complete (133.841s). Train Loss: 132.76

18:50:53 Trainer: Validation loss: 246.77

18:50:53 EpochStopper: Stopper iterating

18:50:53 Trainer: Training epoch 26 beginning

18:53:09 Trainer: Training epoch 26 complete (135.914s). Train Loss: 129.18

18:53:11 Trainer: Validation loss: 247.91

18:53:11 EpochStopper: Stopper iterating

18:53:11 Trainer: Training epoch 27 beginning

18:55:29 Trainer: Training epoch 27 complete (137.310s). Train Loss: 125.94

18:55:31 Trainer: Validation loss: 246.17

18:55:31 EpochStopper: Stopper iterating

18:55:31 Trainer: Training epoch 28 beginning

18:57:48 Trainer: Training epoch 28 complete (137.025s). Train Loss: 123.15

18:57:51 Trainer: Validation loss: 247.77

18:57:51 EpochStopper: Stopper iterating

18:57:51 Trainer: Training epoch 29 beginning

19:00:10 Trainer: Training epoch 29 complete (139.417s). Train Loss: 120.53

19:00:12 Trainer: Validation loss: 246.54

19:00:12 EpochStopper: Stopper iterating

19:00:12 Trainer: Training epoch 30 beginning

19:02:32 Trainer: Training epoch 30 complete (139.418s). Train Loss: 118.06

19:02:35 Trainer: Validation loss: 247.20

19:02:35 EpochStopper: Stopper iterating

19:02:35 Trainer: Training epoch 31 beginning

19:04:55 Trainer: Training epoch 31 complete (140.338s). Train Loss: 115.97

19:04:58 Trainer: Validation loss: 246.89

19:04:58 EpochStopper: Stopper iterating

19:04:58 Trainer: Training epoch 32 beginning

19:07:19 Trainer: Training epoch 32 complete (141.601s). Train Loss: 113.84

19:07:22 Trainer: Validation loss: 245.71

19:07:22 EpochStopper: Stopper iterating

19:07:22 Trainer: Training epoch 33 beginning

19:09:45 Trainer: Training epoch 33 complete (142.805s). Train Loss: 111.83

19:09:48 Trainer: Validation loss: 248.42

19:09:48 EpochStopper: Stopper iterating

19:09:48 Trainer: Training epoch 34 beginning

19:12:11 Trainer: Training epoch 34 complete (143.433s). Train Loss: 110.01

19:12:13 Trainer: Validation loss: 247.69

19:12:13 EpochStopper: Stopper iterating

19:12:13 Trainer: Training epoch 35 beginning

19:14:37 Trainer: Training epoch 35 complete (143.389s). Train Loss: 108.22

19:14:40 Trainer: Validation loss: 246.93

19:14:40 EpochStopper: Stopper iterating

19:14:40 Trainer: Training epoch 36 beginning

19:17:05 Trainer: Training epoch 36 complete (145.555s). Train Loss: 106.60

19:17:08 Trainer: Validation loss: 246.44

19:17:08 EpochStopper: Stopper iterating

19:17:08 Trainer: Training epoch 37 beginning

19:19:34 Trainer: Training epoch 37 complete (146.239s). Train Loss: 105.03

19:19:37 Trainer: Validation loss: 248.39

19:19:37 EpochStopper: Stopper iterating

19:19:37 Trainer: Training epoch 38 beginning

19:22:07 Trainer: Training epoch 38 complete (149.544s). Train Loss: 103.49

19:22:09 Trainer: Validation loss: 247.38

19:22:09 EpochStopper: Stopper iterating

19:22:09 Trainer: Training epoch 39 beginning

19:24:40 Trainer: Training epoch 39 complete (151.178s). Train Loss: 101.84

19:24:43 Trainer: Validation loss: 247.54

19:24:43 EpochStopper: Stopper iterating

19:24:43 Trainer: Training epoch 40 beginning

19:27:17 Trainer: Training epoch 40 complete (153.800s). Train Loss: 100.53

19:27:20 Trainer: Validation loss: 247.51

19:27:20 EpochStopper: Stopper iterating

19:27:20 Trainer: Training epoch 41 beginning

19:29:56 Trainer: Training epoch 41 complete (155.873s). Train Loss: 99.11

19:29:59 Trainer: Validation loss: 248.26

19:29:59 EpochStopper: Stopper iterating

19:29:59 Trainer: Training epoch 42 beginning

19:32:37 Trainer: Training epoch 42 complete (158.505s). Train Loss: 97.83

19:32:40 Trainer: Validation loss: 247.65

19:32:40 EpochStopper: Stopper iterating

19:32:40 Trainer: Training epoch 43 beginning

19:35:20 Trainer: Training epoch 43 complete (160.201s). Train Loss: 96.49

19:35:23 Trainer: Validation loss: 248.44

19:35:23 EpochStopper: Stopper iterating

19:35:23 Trainer: Training epoch 44 beginning

19:38:05 Trainer: Training epoch 44 complete (162.879s). Train Loss: 95.25

19:38:08 Trainer: Validation loss: 250.96

19:38:08 EpochStopper: Stopper iterating

19:38:08 Trainer: Training epoch 45 beginning

19:40:55 Trainer: Training epoch 45 complete (166.626s). Train Loss: 93.95

19:40:57 Trainer: Validation loss: 247.96

19:40:57 EpochStopper: Stopper iterating

19:40:57 Trainer: Training epoch 46 beginning

19:43:47 Trainer: Training epoch 46 complete (169.443s). Train Loss: 92.99

19:43:49 Trainer: Validation loss: 249.40

19:43:49 EpochStopper: Stopper iterating

19:43:49 Trainer: Training epoch 47 beginning

19:46:40 Trainer: Training epoch 47 complete (171.184s). Train Loss: 91.75

19:46:43 Trainer: Validation loss: 249.62

19:46:43 EpochStopper: Stopper iterating

19:46:43 Trainer: Training epoch 48 beginning

19:49:38 Trainer: Training epoch 48 complete (174.878s). Train Loss: 90.66

19:49:41 Trainer: Validation loss: 249.28

19:49:41 EpochStopper: Stopper iterating

19:49:41 Trainer: Training epoch 49 beginning

19:52:36 Trainer: Training epoch 49 complete (175.095s). Train Loss: 89.52

19:52:38 Trainer: Validation loss: 248.53

19:52:38 EpochStopper: Stopper iterating

19:52:38 Trainer: Training epoch 50 beginning

19:55:35 Trainer: Training epoch 50 complete (176.618s). Train Loss: 88.61

19:55:37 Trainer: Validation loss: 250.54

19:55:37 EpochStopper: Stopper iterating

19:55:37 Trainer: Training epoch 51 beginning

19:58:36 Trainer: Training epoch 51 complete (178.354s). Train Loss: 87.81

19:58:38 Trainer: Validation loss: 250.06

19:58:38 EpochStopper: Stopper iterating

19:58:38 Trainer: Training epoch 52 beginning

20:01:38 Trainer: Training epoch 52 complete (179.148s). Train Loss: 86.88

20:01:40 Trainer: Validation loss: 249.73

20:01:40 EpochStopper: Stopper iterating

20:01:40 Trainer: Training epoch 53 beginning

20:04:41 Trainer: Training epoch 53 complete (180.179s). Train Loss: 85.95

20:04:43 Trainer: Validation loss: 250.76

20:04:43 EpochStopper: Stopper iterating

20:04:43 Trainer: Training epoch 54 beginning

20:07:47 Trainer: Training epoch 54 complete (183.450s). Train Loss: 85.02

20:07:50 Trainer: Validation loss: 250.83

20:07:50 EpochStopper: Stopper iterating

20:07:50 Trainer: Training epoch 55 beginning

20:10:54 Trainer: Training epoch 55 complete (184.377s). Train Loss: 84.26

20:10:57 Trainer: Validation loss: 249.53

20:10:57 EpochStopper: Stopper iterating

20:10:57 Trainer: Training epoch 56 beginning

20:14:04 Trainer: Training epoch 56 complete (187.807s). Train Loss: 83.30

20:14:07 Trainer: Validation loss: 250.49

20:14:07 EpochStopper: Stopper iterating

20:14:07 Trainer: Training epoch 57 beginning

20:17:19 Trainer: Training epoch 57 complete (191.671s). Train Loss: 82.55

20:17:21 Trainer: Validation loss: 251.57

20:17:21 EpochStopper: Stopper iterating

20:17:21 Trainer: Training epoch 58 beginning

20:20:35 Trainer: Training epoch 58 complete (193.452s). Train Loss: 81.61

20:20:37 Trainer: Validation loss: 249.26

20:20:37 EpochStopper: Stopper iterating

20:20:37 Trainer: Training epoch 59 beginning

20:23:54 Trainer: Training epoch 59 complete (196.828s). Train Loss: 81.08

20:23:57 Trainer: Validation loss: 250.90

20:23:57 EpochStopper: Stopper iterating

20:23:57 Trainer: Training epoch 60 beginning

20:27:18 Trainer: Training epoch 60 complete (200.944s). Train Loss: 80.38

20:27:21 Trainer: Validation loss: 251.04

20:27:21 EpochStopper: Stopper iterating

20:27:21 Trainer: Training epoch 61 beginning

20:30:45 Trainer: Training epoch 61 complete (203.756s). Train Loss: 79.61

20:30:47 Trainer: Validation loss: 250.50

20:30:47 EpochStopper: Stopper iterating

20:30:47 Trainer: Training epoch 62 beginning

20:34:15 Trainer: Training epoch 62 complete (207.631s). Train Loss: 79.01

20:34:17 Trainer: Validation loss: 250.51

20:34:17 EpochStopper: Stopper iterating

20:34:17 Trainer: Training epoch 63 beginning

20:37:49 Trainer: Training epoch 63 complete (212.083s). Train Loss: 78.28

20:37:52 Trainer: Validation loss: 250.47

20:37:52 EpochStopper: Stopper iterating

20:37:52 Trainer: Training epoch 64 beginning

20:41:25 Trainer: Training epoch 64 complete (213.378s). Train Loss: 77.60

20:41:28 Trainer: Validation loss: 251.73

20:41:28 EpochStopper: Stopper iterating

20:41:28 Trainer: Training epoch 65 beginning

20:45:02 Trainer: Training epoch 65 complete (214.109s). Train Loss: 76.99

20:45:05 Trainer: Validation loss: 251.25

20:45:05 EpochStopper: Stopper iterating

20:45:05 Trainer: Training epoch 66 beginning

20:48:40 Trainer: Training epoch 66 complete (215.239s). Train Loss: 76.51

20:48:43 Trainer: Validation loss: 250.94

20:48:43 EpochStopper: Stopper iterating

20:48:43 Trainer: Training epoch 67 beginning

20:52:16 Trainer: Training epoch 67 complete (213.373s). Train Loss: 75.80

20:52:19 Trainer: Validation loss: 253.14

20:52:19 EpochStopper: Stopper iterating

20:52:19 Trainer: Training epoch 68 beginning

20:55:54 Trainer: Training epoch 68 complete (215.672s). Train Loss: 75.11

20:55:57 Trainer: Validation loss: 249.92

20:55:57 EpochStopper: Stopper iterating

20:55:57 Trainer: Training epoch 69 beginning

20:59:32 Trainer: Training epoch 69 complete (215.390s). Train Loss: 74.62

20:59:35 Trainer: Validation loss: 251.99

20:59:35 EpochStopper: Stopper iterating

20:59:35 Trainer: Training epoch 70 beginning

21:03:09 Trainer: Training epoch 70 complete (213.711s). Train Loss: 73.88

21:03:12 Trainer: Validation loss: 251.08

21:03:12 EpochStopper: Stopper iterating

21:03:12 Trainer: Training epoch 71 beginning

21:06:48 Trainer: Training epoch 71 complete (216.113s). Train Loss: 73.47

21:06:51 Trainer: Validation loss: 251.13

21:06:51 EpochStopper: Stopper iterating

21:06:51 Trainer: Training epoch 72 beginning

21:10:26 Trainer: Training epoch 72 complete (215.717s). Train Loss: 72.99

21:10:29 Trainer: Validation loss: 251.00

21:10:29 EpochStopper: Stopper iterating

21:10:29 Trainer: Training epoch 73 beginning

21:14:04 Trainer: Training epoch 73 complete (214.856s). Train Loss: 72.24

21:14:07 Trainer: Validation loss: 251.53

21:14:07 EpochStopper: Stopper iterating

21:14:07 Trainer: Training epoch 74 beginning

21:17:43 Trainer: Training epoch 74 complete (216.016s). Train Loss: 71.82

21:17:45 Trainer: Validation loss: 252.19

21:17:45 EpochStopper: Stopper iterating

21:17:45 Trainer: Training epoch 75 beginning

21:21:23 Trainer: Training epoch 75 complete (217.163s). Train Loss: 71.35

21:21:25 Trainer: Validation loss: 251.84

21:21:25 EpochStopper: Stopper iterating

21:21:25 Trainer: Training epoch 76 beginning

21:24:59 Trainer: Training epoch 76 complete (214.037s). Train Loss: 70.78

21:25:02 Trainer: Validation loss: 252.15

21:25:02 EpochStopper: Stopper iterating

21:25:02 Trainer: Training epoch 77 beginning

21:28:34 Trainer: Training epoch 77 complete (211.827s). Train Loss: 70.42

21:28:36 Trainer: Validation loss: 251.28

21:28:36 EpochStopper: Stopper iterating

21:28:36 Trainer: Training epoch 78 beginning

21:32:11 Trainer: Training epoch 78 complete (214.615s). Train Loss: 69.96

21:32:13 Trainer: Validation loss: 251.22

21:32:13 EpochStopper: Stopper iterating

21:32:13 Trainer: Training epoch 79 beginning

21:35:46 Trainer: Training epoch 79 complete (212.991s). Train Loss: 69.51

21:35:49 Trainer: Validation loss: 252.64

21:35:49 EpochStopper: Stopper iterating

21:35:49 Trainer: Training epoch 80 beginning

21:39:23 Trainer: Training epoch 80 complete (214.164s). Train Loss: 68.99

21:39:26 Trainer: Validation loss: 252.12

21:39:26 EpochStopper: Stopper iterating

21:39:26 Trainer: Training epoch 81 beginning

21:42:58 Trainer: Training epoch 81 complete (212.339s). Train Loss: 68.62

21:43:01 Trainer: Validation loss: 251.99

21:43:01 EpochStopper: Stopper iterating

21:43:01 Trainer: Training epoch 82 beginning

21:46:33 Trainer: Training epoch 82 complete (212.004s). Train Loss: 68.14

21:46:36 Trainer: Validation loss: 251.65

21:46:36 EpochStopper: Stopper iterating

21:46:36 Trainer: Training epoch 83 beginning

21:50:08 Trainer: Training epoch 83 complete (212.528s). Train Loss: 67.68

21:50:11 Trainer: Validation loss: 252.40

21:50:11 EpochStopper: Stopper iterating

21:50:11 Trainer: Training epoch 84 beginning

21:53:44 Trainer: Training epoch 84 complete (213.789s). Train Loss: 67.45

21:53:47 Trainer: Validation loss: 253.30

21:53:47 EpochStopper: Stopper iterating

21:53:47 Trainer: Training epoch 85 beginning

21:57:21 Trainer: Training epoch 85 complete (213.907s). Train Loss: 66.74

21:57:24 Trainer: Validation loss: 252.35

21:57:24 EpochStopper: Stopper iterating

21:57:24 Trainer: Training epoch 86 beginning

22:00:58 Trainer: Training epoch 86 complete (213.658s). Train Loss: 66.46

22:01:00 Trainer: Validation loss: 252.73

22:01:00 EpochStopper: Stopper iterating

22:01:00 Trainer: Training epoch 87 beginning

22:04:32 Trainer: Training epoch 87 complete (211.902s). Train Loss: 65.97

22:04:35 Trainer: Validation loss: 252.72

22:04:35 EpochStopper: Stopper iterating

22:04:35 Trainer: Training epoch 88 beginning

22:08:07 Trainer: Training epoch 88 complete (211.536s). Train Loss: 65.69

22:08:09 Trainer: Validation loss: 252.56

22:08:09 EpochStopper: Stopper iterating

22:08:09 Trainer: Training epoch 89 beginning

22:11:41 Trainer: Training epoch 89 complete (212.025s). Train Loss: 65.21

22:11:44 Trainer: Validation loss: 252.04

22:11:44 EpochStopper: Stopper iterating

22:11:44 Trainer: Training epoch 90 beginning

22:15:14 Trainer: Training epoch 90 complete (210.212s). Train Loss: 64.85

22:15:17 Trainer: Validation loss: 251.69

22:15:17 EpochStopper: Stopper iterating

22:15:17 Trainer: Training epoch 91 beginning

22:18:48 Trainer: Training epoch 91 complete (211.060s). Train Loss: 64.52

22:18:51 Trainer: Validation loss: 251.63

22:18:51 EpochStopper: Stopper iterating

22:18:51 Trainer: Training epoch 92 beginning

22:22:21 Trainer: Training epoch 92 complete (210.433s). Train Loss: 64.21

22:22:25 Trainer: Validation loss: 252.78

22:22:25 EpochStopper: Stopper iterating

22:22:25 Trainer: Training epoch 93 beginning

22:25:54 Trainer: Training epoch 93 complete (209.705s). Train Loss: 63.74

22:25:57 Trainer: Validation loss: 251.72

22:25:57 EpochStopper: Stopper iterating

22:25:57 Trainer: Training epoch 94 beginning

22:29:27 Trainer: Training epoch 94 complete (210.348s). Train Loss: 63.47

22:29:30 Trainer: Validation loss: 253.70

22:29:30 EpochStopper: Stopper iterating

22:29:30 Trainer: Training epoch 95 beginning

22:33:02 Trainer: Training epoch 95 complete (211.809s). Train Loss: 63.06

22:33:05 Trainer: Validation loss: 252.88

22:33:05 EpochStopper: Stopper iterating

22:33:05 Trainer: Training epoch 96 beginning

22:36:34 Trainer: Training epoch 96 complete (209.789s). Train Loss: 62.71

22:36:38 Trainer: Validation loss: 252.82

22:36:38 EpochStopper: Stopper iterating

22:36:38 Trainer: Training epoch 97 beginning

22:40:09 Trainer: Training epoch 97 complete (211.457s). Train Loss: 62.35

22:40:12 Trainer: Validation loss: 253.60

22:40:12 EpochStopper: Stopper iterating

22:40:12 Trainer: Training epoch 98 beginning

22:43:42 Trainer: Training epoch 98 complete (210.444s). Train Loss: 62.05

22:43:45 Trainer: Validation loss: 253.63

22:43:45 EpochStopper: Stopper iterating

22:43:45 Trainer: Training epoch 99 beginning

22:47:15 Trainer: Training epoch 99 complete (209.767s). Train Loss: 61.54

22:47:17 Trainer: Validation loss: 252.58

22:47:17 EpochStopper: Stopper iterating

22:47:17 Trainer: Training epoch 100 beginning

22:50:47 Trainer: Training epoch 100 complete (210.298s). Train Loss: 61.40

22:50:50 Trainer: Validation loss: 253.26

22:50:50 EpochStopper: Stopper iterating

22:50:50 Trainer: Training epoch 101 beginning

22:54:21 Trainer: Training epoch 101 complete (211.455s). Train Loss: 60.96

22:54:24 Trainer: Validation loss: 253.72

22:54:24 EpochStopper: Stopper iterating

22:54:24 PlateauStopper: Loss plateauing (Patience=1/20).

22:54:24 Trainer: Saving model checkpoint.

22:54:24 MHSimNN: Model saved to ./experiments/SimNN/041023180043/checkpoint_model.pt

22:54:24 Trainer: Training epoch 102 beginning

22:57:56 Trainer: Training epoch 102 complete (211.688s). Train Loss: 60.69

22:57:59 Trainer: Validation loss: 252.98

22:57:59 EpochStopper: Stopper iterating

22:57:59 Trainer: Training epoch 103 beginning

23:01:29 Trainer: Training epoch 103 complete (210.226s). Train Loss: 60.35

23:01:31 Trainer: Validation loss: 253.86

23:01:31 EpochStopper: Stopper iterating

23:01:31 PlateauStopper: Loss plateauing (Patience=1/20).

23:01:31 Trainer: Saving model checkpoint.

23:01:32 MHSimNN: Model saved to ./experiments/SimNN/041023180043/checkpoint_model.pt

23:01:32 Trainer: Training epoch 104 beginning

23:05:02 Trainer: Training epoch 104 complete (210.215s). Train Loss: 60.13

23:05:05 Trainer: Validation loss: 254.24

23:05:05 EpochStopper: Stopper iterating

23:05:05 PlateauStopper: Loss plateauing (Patience=2/20).

23:05:05 Trainer: Training epoch 105 beginning

23:08:37 Trainer: Training epoch 105 complete (212.570s). Train Loss: 59.67

23:08:40 Trainer: Validation loss: 253.09

23:08:40 EpochStopper: Stopper iterating

23:08:40 PlateauStopper: Loss plateauing (Patience=3/20).

23:08:40 Trainer: Training epoch 106 beginning

23:12:10 Trainer: Training epoch 106 complete (209.487s). Train Loss: 59.73

23:12:12 Trainer: Validation loss: 252.63

23:12:12 EpochStopper: Stopper iterating

23:12:12 Trainer: Training epoch 107 beginning

23:15:42 Trainer: Training epoch 107 complete (209.443s). Train Loss: 59.13

23:15:45 Trainer: Validation loss: 252.73

23:15:45 EpochStopper: Stopper iterating

23:15:45 PlateauStopper: Loss plateauing (Patience=1/20).

23:15:45 Trainer: Saving model checkpoint.

23:15:45 MHSimNN: Model saved to ./experiments/SimNN/041023180043/checkpoint_model.pt

23:15:45 Trainer: Training epoch 108 beginning

23:19:15 Trainer: Training epoch 108 complete (209.858s). Train Loss: 58.91

23:19:17 Trainer: Validation loss: 252.38

23:19:17 EpochStopper: Stopper iterating

23:19:17 Trainer: Training epoch 109 beginning

23:22:48 Trainer: Training epoch 109 complete (210.126s). Train Loss: 58.49

23:22:51 Trainer: Validation loss: 254.25

23:22:51 EpochStopper: Stopper iterating

23:22:51 PlateauStopper: Loss plateauing (Patience=1/20).

23:22:51 Trainer: Saving model checkpoint.

23:22:51 MHSimNN: Model saved to ./experiments/SimNN/041023180043/checkpoint_model.pt

23:22:51 Trainer: Training epoch 110 beginning

23:26:22 Trainer: Training epoch 110 complete (210.843s). Train Loss: 58.29

23:26:24 Trainer: Validation loss: 253.60

23:26:24 EpochStopper: Stopper iterating

23:26:24 PlateauStopper: Loss plateauing (Patience=2/20).

23:26:24 Trainer: Training epoch 111 beginning

23:29:54 Trainer: Training epoch 111 complete (209.531s). Train Loss: 58.11

23:29:57 Trainer: Validation loss: 253.52

23:29:57 EpochStopper: Stopper iterating

23:29:57 PlateauStopper: Loss plateauing (Patience=3/20).

23:29:57 Trainer: Training epoch 112 beginning

23:33:26 Trainer: Training epoch 112 complete (209.379s). Train Loss: 57.84

23:33:29 Trainer: Validation loss: 253.42

23:33:29 EpochStopper: Stopper iterating

23:33:29 PlateauStopper: Loss plateauing (Patience=4/20).

23:33:29 Trainer: Training epoch 113 beginning

23:36:59 Trainer: Training epoch 113 complete (210.850s). Train Loss: 57.58

23:37:02 Trainer: Validation loss: 252.42

23:37:02 EpochStopper: Stopper iterating

23:37:02 PlateauStopper: Loss plateauing (Patience=5/20).

23:37:02 Trainer: Training epoch 114 beginning

23:40:33 Trainer: Training epoch 114 complete (210.251s). Train Loss: 57.28

23:40:35 Trainer: Validation loss: 253.16

23:40:35 EpochStopper: Stopper iterating

23:40:35 PlateauStopper: Loss plateauing (Patience=6/20).

23:40:35 Trainer: Training epoch 115 beginning

23:44:06 Trainer: Training epoch 115 complete (210.564s). Train Loss: 57.05

23:44:08 Trainer: Validation loss: 253.44

23:44:08 EpochStopper: Stopper iterating

23:44:08 PlateauStopper: Loss plateauing (Patience=7/20).

23:44:08 Trainer: Training epoch 116 beginning

23:47:39 Trainer: Training epoch 116 complete (210.047s). Train Loss: 56.65

23:47:41 Trainer: Validation loss: 253.47

23:47:41 EpochStopper: Stopper iterating

23:47:41 PlateauStopper: Loss plateauing (Patience=8/20).

23:47:41 Trainer: Training epoch 117 beginning

23:51:12 Trainer: Training epoch 117 complete (210.381s). Train Loss: 56.53

23:51:15 Trainer: Validation loss: 253.31

23:51:15 EpochStopper: Stopper iterating

23:51:15 PlateauStopper: Loss plateauing (Patience=9/20).

23:51:15 Trainer: Training epoch 118 beginning

23:54:45 Trainer: Training epoch 118 complete (210.385s). Train Loss: 56.16

23:54:47 Trainer: Validation loss: 254.23

23:54:47 EpochStopper: Stopper iterating

23:54:47 PlateauStopper: Loss plateauing (Patience=10/20).

23:54:47 Trainer: Training epoch 119 beginning

23:58:17 Trainer: Training epoch 119 complete (209.804s). Train Loss: 55.83

23:58:20 Trainer: Validation loss: 253.62

23:58:20 EpochStopper: Stopper iterating

23:58:20 PlateauStopper: Loss plateauing (Patience=11/20).

23:58:20 Trainer: Training epoch 120 beginning

00:01:50 Trainer: Training epoch 120 complete (209.770s). Train Loss: 55.76

00:01:53 Trainer: Validation loss: 253.64

00:01:53 EpochStopper: Stopper iterating

00:01:53 PlateauStopper: Loss plateauing (Patience=12/20).

00:01:53 Trainer: Training epoch 121 beginning

00:05:22 Trainer: Training epoch 121 complete (209.757s). Train Loss: 55.45

00:05:25 Trainer: Validation loss: 253.93

00:05:25 EpochStopper: Stopper iterating

00:05:25 PlateauStopper: Loss plateauing (Patience=13/20).

00:05:25 Trainer: Training epoch 122 beginning

00:08:54 Trainer: Training epoch 122 complete (208.603s). Train Loss: 55.24

00:08:56 Trainer: Validation loss: 253.98

00:08:56 EpochStopper: Stopper iterating

00:08:56 PlateauStopper: Loss plateauing (Patience=14/20).

00:08:56 Trainer: Training epoch 123 beginning

00:12:26 Trainer: Training epoch 123 complete (210.079s). Train Loss: 54.97

00:12:29 Trainer: Validation loss: 254.23

00:12:29 EpochStopper: Stopper iterating

00:12:29 PlateauStopper: Loss plateauing (Patience=15/20).

00:12:29 Trainer: Training epoch 124 beginning

00:15:59 Trainer: Training epoch 124 complete (209.887s). Train Loss: 54.73

00:16:02 Trainer: Validation loss: 254.03

00:16:02 EpochStopper: Stopper iterating

00:16:02 PlateauStopper: Loss plateauing (Patience=16/20).

00:16:02 Trainer: Training epoch 125 beginning

00:19:31 Trainer: Training epoch 125 complete (209.406s). Train Loss: 54.58

00:19:34 Trainer: Validation loss: 253.16

00:19:34 EpochStopper: Stopper iterating

00:19:34 PlateauStopper: Loss plateauing (Patience=17/20).

00:19:34 Trainer: Training epoch 126 beginning

00:23:04 Trainer: Training epoch 126 complete (210.028s). Train Loss: 54.19

00:23:06 Trainer: Validation loss: 254.92

00:23:06 EpochStopper: Stopper iterating

00:23:06 PlateauStopper: Loss plateauing (Patience=18/20).

00:23:06 Trainer: Training epoch 127 beginning

00:26:34 Trainer: Training epoch 127 complete (207.561s). Train Loss: 54.09

00:26:36 Trainer: Validation loss: 254.52

00:26:36 EpochStopper: Stopper iterating

00:26:36 PlateauStopper: Loss plateauing (Patience=19/20).

00:26:36 Trainer: Training epoch 128 beginning

00:30:07 Trainer: Training epoch 128 complete (210.568s). Train Loss: 54.00

00:30:09 Trainer: Validation loss: 254.71

00:30:09 EpochStopper: Stopper iterating

00:30:09 PlateauStopper: Loss plateauing (Patience=20/20).

00:30:09 Trainer: Training epoch 129 beginning

00:33:41 Trainer: Training epoch 129 complete (211.641s). Train Loss: 53.47

00:33:44 Trainer: Validation loss: 254.83

00:33:44 EpochStopper: Stopper iterating

00:33:44 PlateauStopper: Loss plateauing (Patience=21/20).

00:33:44 PlateauStopper: Stopping condition met.

00:33:53 Trainer: Final train-set loss 53.322

00:33:55 Trainer: Final validation-set loss 254.832

00:33:55 Trainer: Training complete. Model trained for 130 epochs. Training time: 392.43 min

00:33:56 MHSimNN: Model saved to ./experiments/SimNN/041023180043/model.pt

00:33:56 main: Beginning evaluation of model...

00:33:56 main: Getting predictions for train set...

00:34:20 main: Getting predictions for validation set...

00:34:26 main: Getting predictions for test set...

00:34:29 main: {
    "train": {
        "n": 276158,
        "range": {
            "mean_squared_error": 0.26765899148964345,
            "mean_absolute_error": 0.042052631526587524
        },
        "cost": {
            "mean_squared_error": 26261.953436961823,
            "mean_absolute_error": 96.56746583470502
        },
        "velocity": {
            "mean_squared_error": 312.4910079881632,
            "mean_absolute_error": 3.0046934265227363
        },
        "result": {
            "accuracy_score": 0.9977585295374387
        }
    },
    "val": {
        "n": 69040,
        "range": {
            "mean_squared_error": 2.4571786297337703,
            "mean_absolute_error": 0.25843179575437597
        },
        "cost": {
            "mean_squared_error": 66233.63269814332,
            "mean_absolute_error": 165.4727084799686
        },
        "velocity": {
            "mean_squared_error": 3099.806080319249,
            "mean_absolute_error": 14.052840255116257
        },
        "result": {
            "accuracy_score": 0.9836181923522596
        }
    },
    "test": {
        "n": 38356,
        "range": {
            "mean_squared_error": 2.694250183597244,
            "mean_absolute_error": 0.27682025670399535
        },
        "cost": {
            "mean_squared_error": 66563.25965406682,
            "mean_absolute_error": 165.53276271583366
        },
        "velocity": {
            "mean_squared_error": 2877.7430962819717,
            "mean_absolute_error": 13.790168708824542
        },
        "result": {
            "accuracy_score": 0.9828188549379497
        }
    },
    "stable": {
        "train": {
            "n": 18505,
            "range": {
                "mean_squared_error": 2.2510399005883355,
                "mean_absolute_error": 0.3067102866991909
            },
            "cost": {
                "mean_squared_error": 10276.265833337544,
                "mean_absolute_error": 55.28695873475919
            },
            "velocity": {
                "mean_squared_error": 4.630250334259834,
                "mean_absolute_error": 0.9281345429790242
            },
            "result": {
                "accuracy_score": 0.9992434477168333
            },
            "n_stable": 18505
        },
        "val": {
            "n": 4553,
            "range": {
                "mean_squared_error": 16.423239328600257,
                "mean_absolute_error": 1.714296259092101
            },
            "cost": {
                "mean_squared_error": 25778.61615955221,
                "mean_absolute_error": 94.92257256762369
            },
            "velocity": {
                "mean_squared_error": 40.59384737733928,
                "mean_absolute_error": 3.071610648266017
            },
            "result": {
                "accuracy_score": 0.8961124533274764
            },
            "n_stable": 4553
        },
        "test": {
            "n": 2752,
            "range": {
                "mean_squared_error": 16.59323323726195,
                "mean_absolute_error": 1.7341907544567625
            },
            "cost": {
                "mean_squared_error": 23935.310295043535,
                "mean_absolute_error": 93.85732402357944
            },
            "velocity": {
                "mean_squared_error": 44.63610709514944,
                "mean_absolute_error": 3.1069173294790957
            },
            "result": {
                "accuracy_score": 0.8957122093023255
            },
            "n_stable": 2752
        }
    }
}

00:34:29 Hyperparams: Copy of hyperparams file saved to ./experiments/SimNN/041023180043/nn_hparams.json

00:34:29 main: Experiment 041023180043 completed

